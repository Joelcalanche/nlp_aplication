{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "celtic-brass",
   "metadata": {},
   "source": [
    "## `Text` Sumarrization using NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-probability",
   "metadata": {},
   "source": [
    "**What is text summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-liquid",
   "metadata": {},
   "source": [
    "Text summarization is the process of distiling the most important information from a source text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-acting",
   "metadata": {},
   "source": [
    "**Why automatic text summarization**\n",
    "* Summaries reduce reading time.\n",
    "* When researching documents, summaries make the selection process easier.\n",
    "* Automatic summarization improves the effectiveness of indexing.\n",
    "* Automatic summarization algorithms are less biasd than human summarizers.\n",
    "* Personalized summaries are useful in question-answering systems as they provide personalized information.\n",
    "\n",
    "* Using automatic or semi-automatic summarization systems enables commercial abstract services to increase the number of text documents they are able to process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-norman",
   "metadata": {},
   "source": [
    "**Type of summarization**\n",
    "\n",
    "* Base on input type\n",
    "    * Single Document\n",
    "    * Multi Document\n",
    "* Base on Output type\n",
    "    * Extractive\n",
    "    * Abstractive\n",
    "    \n",
    "* Base on the Purpose\n",
    "    * Generic\n",
    "    * Domain specific\n",
    "    * Query-based\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-anime",
   "metadata": {},
   "source": [
    "**How to do text summarization**\n",
    "- Text cleaning\n",
    "- Sentence Tokenization\n",
    "- Word tokenization\n",
    "\n",
    "- Word-frequency table\n",
    "- Clustering\n",
    "\n",
    "- Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-infection",
   "metadata": {},
   "source": [
    "**Text**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "every-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "\n",
    "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
    "\n",
    "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
    "\n",
    "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[8] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-private",
   "metadata": {},
   "source": [
    "## Let's Get Started with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "charged-health",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\calanche\\miniconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (4.59.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (0.7.5)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Using cached srsly-2.4.2-cp38-cp38-win_amd64.whl (452 kB)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (8.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Installing collected packages: srsly\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 1.0.5\n",
      "    Uninstalling srsly-1.0.5:\n",
      "      Successfully uninstalled srsly-1.0.5\n",
      "Successfully installed srsly-2.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "en-core-web-sm 2.3.1 requires spacy<2.4.0,>=2.3.0, but you have spacy 3.2.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.3.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\calanche\\\\AppData\\\\Local\\\\Temp\\\\pip-uninstall-r39xwwei\\\\msgpack\\\\_packer.cp38-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting spacy<2.4.0,>=2.3.0\n",
      "  Downloading spacy-2.3.7-cp38-cp38-win_amd64.whl (9.7 MB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.25.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (52.0.0.post20210125)\n",
      "Collecting srsly<1.1.0,>=1.0.2\n",
      "  Downloading srsly-1.0.5-cp38-cp38-win_amd64.whl (178 kB)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.59.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.21.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.6)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.9.0)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting thinc<7.5.0,>=7.4.1\n",
      "  Downloading thinc-7.4.5-cp38-cp38-win_amd64.whl (910 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\calanche\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Installing collected packages: srsly, catalogue, thinc, spacy\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 2.4.2\n",
      "    Uninstalling srsly-2.4.2:\n",
      "      Successfully uninstalled srsly-2.4.2\n"
     ]
    }
   ],
   "source": [
    " !pip install -U spacy\n",
    "\n",
    " !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exact-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "combined-alert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['more',\n",
       " 'whether',\n",
       " 'twenty',\n",
       " 'below',\n",
       " 'behind',\n",
       " 'whereby',\n",
       " 'myself',\n",
       " 'herein',\n",
       " 'besides',\n",
       " 'becomes',\n",
       " 'never',\n",
       " 'and',\n",
       " 'our',\n",
       " \"'d\",\n",
       " 'beside',\n",
       " 'ourselves',\n",
       " 'so',\n",
       " \"'s\",\n",
       " 'any',\n",
       " 'yourselves',\n",
       " 'same',\n",
       " 'their',\n",
       " 'under',\n",
       " 'yourself',\n",
       " '‘d',\n",
       " 'out',\n",
       " 'empty',\n",
       " 'towards',\n",
       " '’re',\n",
       " 'might',\n",
       " '’ve',\n",
       " 'himself',\n",
       " 'herself',\n",
       " 'of',\n",
       " 'off',\n",
       " 'whoever',\n",
       " 'serious',\n",
       " 'using',\n",
       " 'everywhere',\n",
       " 'them',\n",
       " 'seem',\n",
       " 'before',\n",
       " 'perhaps',\n",
       " 'been',\n",
       " 'for',\n",
       " 'part',\n",
       " 'when',\n",
       " 'cannot',\n",
       " 'nevertheless',\n",
       " 'noone',\n",
       " 'therein',\n",
       " 'whence',\n",
       " 'above',\n",
       " 'always',\n",
       " 'where',\n",
       " 'former',\n",
       " 'became',\n",
       " 'a',\n",
       " 'quite',\n",
       " 'done',\n",
       " '‘ll',\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " 'your',\n",
       " 'there',\n",
       " 'thru',\n",
       " 'i',\n",
       " 'again',\n",
       " 'eight',\n",
       " 'somewhere',\n",
       " 'six',\n",
       " 'hers',\n",
       " 'own',\n",
       " 'per',\n",
       " 'then',\n",
       " 'mine',\n",
       " 'if',\n",
       " 'become',\n",
       " 'which',\n",
       " 'therefore',\n",
       " 'several',\n",
       " 'we',\n",
       " 'am',\n",
       " 're',\n",
       " 'toward',\n",
       " 'seems',\n",
       " 'only',\n",
       " 'why',\n",
       " 'almost',\n",
       " 'take',\n",
       " 'would',\n",
       " 'fifteen',\n",
       " 'from',\n",
       " 'my',\n",
       " 'made',\n",
       " 'on',\n",
       " 'beforehand',\n",
       " 'among',\n",
       " 'will',\n",
       " 'yet',\n",
       " 'upon',\n",
       " 'through',\n",
       " 'hereby',\n",
       " 'two',\n",
       " 'three',\n",
       " 'had',\n",
       " 'moreover',\n",
       " 'between',\n",
       " 'anywhere',\n",
       " 'whenever',\n",
       " '‘s',\n",
       " 'did',\n",
       " '’d',\n",
       " 'who',\n",
       " 'ever',\n",
       " \"n't\",\n",
       " 'down',\n",
       " 'each',\n",
       " 'via',\n",
       " 'few',\n",
       " 'to',\n",
       " 'seeming',\n",
       " 'such',\n",
       " 'they',\n",
       " 'beyond',\n",
       " 'side',\n",
       " 'someone',\n",
       " 'he',\n",
       " 'give',\n",
       " 'together',\n",
       " 'afterwards',\n",
       " 'not',\n",
       " 'some',\n",
       " 'next',\n",
       " '‘ve',\n",
       " 'up',\n",
       " 'put',\n",
       " \"'re\",\n",
       " 'full',\n",
       " 'during',\n",
       " 'within',\n",
       " 'bottom',\n",
       " 'really',\n",
       " 'twelve',\n",
       " 'back',\n",
       " 'meanwhile',\n",
       " 'elsewhere',\n",
       " 'may',\n",
       " 'by',\n",
       " 'forty',\n",
       " 'after',\n",
       " 'hundred',\n",
       " 'move',\n",
       " 'nothing',\n",
       " 'hereupon',\n",
       " 'with',\n",
       " 'sometimes',\n",
       " 'here',\n",
       " 'both',\n",
       " 'anyway',\n",
       " 'much',\n",
       " 'another',\n",
       " 'whole',\n",
       " 'regarding',\n",
       " 'first',\n",
       " 'until',\n",
       " 'already',\n",
       " 'ten',\n",
       " 'along',\n",
       " 'go',\n",
       " 'eleven',\n",
       " 'latter',\n",
       " 'it',\n",
       " 'since',\n",
       " 'than',\n",
       " 'also',\n",
       " 'in',\n",
       " 'mostly',\n",
       " 'whereas',\n",
       " 'unless',\n",
       " 'else',\n",
       " 'latterly',\n",
       " 'that',\n",
       " 'still',\n",
       " 'do',\n",
       " 'me',\n",
       " 'none',\n",
       " 'used',\n",
       " 'alone',\n",
       " 'other',\n",
       " 'those',\n",
       " 'while',\n",
       " 'last',\n",
       " 'ours',\n",
       " 'these',\n",
       " 'various',\n",
       " 'what',\n",
       " 'third',\n",
       " 'too',\n",
       " 'most',\n",
       " 'show',\n",
       " 'n‘t',\n",
       " '’s',\n",
       " 'you',\n",
       " 'as',\n",
       " 'whatever',\n",
       " 'was',\n",
       " 'whither',\n",
       " 'amongst',\n",
       " 'because',\n",
       " 'how',\n",
       " 'are',\n",
       " 'is',\n",
       " 'see',\n",
       " 'she',\n",
       " 'top',\n",
       " 'fifty',\n",
       " 'very',\n",
       " 'us',\n",
       " 'now',\n",
       " 'thus',\n",
       " 'n’t',\n",
       " 'could',\n",
       " 'does',\n",
       " 'although',\n",
       " 'often',\n",
       " 'can',\n",
       " 'themselves',\n",
       " \"'ve\",\n",
       " 'further',\n",
       " 'well',\n",
       " 'get',\n",
       " 'less',\n",
       " 'others',\n",
       " 'rather',\n",
       " 'seemed',\n",
       " 'keep',\n",
       " 'must',\n",
       " 'thereby',\n",
       " 'around',\n",
       " 'yours',\n",
       " 'her',\n",
       " 'make',\n",
       " '‘m',\n",
       " 'neither',\n",
       " 'name',\n",
       " 'please',\n",
       " 'nowhere',\n",
       " 'sometime',\n",
       " 'whereafter',\n",
       " 'except',\n",
       " '’ll',\n",
       " 'everyone',\n",
       " 'itself',\n",
       " 'front',\n",
       " 'him',\n",
       " 'throughout',\n",
       " 'even',\n",
       " 'enough',\n",
       " 'thereupon',\n",
       " 'whose',\n",
       " 'one',\n",
       " 'something',\n",
       " 'be',\n",
       " 'anyhow',\n",
       " 'into',\n",
       " 'hence',\n",
       " 'anything',\n",
       " 'without',\n",
       " 'either',\n",
       " 'wherever',\n",
       " 'doing',\n",
       " 'an',\n",
       " 'his',\n",
       " 'four',\n",
       " 'should',\n",
       " 'across',\n",
       " 'thence',\n",
       " 'call',\n",
       " 'however',\n",
       " 'thereafter',\n",
       " 'against',\n",
       " 'ca',\n",
       " 'wherein',\n",
       " '’m',\n",
       " 'were',\n",
       " 'just',\n",
       " 'five',\n",
       " 'nor',\n",
       " 'say',\n",
       " 'over',\n",
       " 'its',\n",
       " 'becoming',\n",
       " 'many',\n",
       " 'have',\n",
       " 'no',\n",
       " 'at',\n",
       " '‘re',\n",
       " 'everything',\n",
       " 'all',\n",
       " 'nobody',\n",
       " 'due',\n",
       " 'or',\n",
       " 'this',\n",
       " 'nine',\n",
       " 'otherwise',\n",
       " 'the',\n",
       " 'whereupon',\n",
       " 'hereafter',\n",
       " 'sixty',\n",
       " 'formerly',\n",
       " 'once',\n",
       " 'though',\n",
       " 'namely',\n",
       " 'has',\n",
       " 'about',\n",
       " 'somehow',\n",
       " 'onto',\n",
       " 'whom',\n",
       " 'every',\n",
       " 'anyone',\n",
       " 'being',\n",
       " 'least',\n",
       " 'amount',\n",
       " 'indeed',\n",
       " 'but']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords = STOP_WORDS\n",
    "# stopwords\n",
    "stopwords = list(STOP_WORDS)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "helpful-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLp model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "specified-tonight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
       "\n",
       "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
       "\n",
       "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[8] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.\n",
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "virtual-brighton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "There"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "virtual-staff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n',\n",
       " 'There',\n",
       " 'are',\n",
       " 'broadly',\n",
       " 'two',\n",
       " 'types',\n",
       " 'of',\n",
       " 'extractive',\n",
       " 'summarization',\n",
       " 'tasks',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'what',\n",
       " 'the',\n",
       " 'summarization',\n",
       " 'program',\n",
       " 'focuses',\n",
       " 'on',\n",
       " '.',\n",
       " 'The',\n",
       " 'first',\n",
       " 'is',\n",
       " 'generic',\n",
       " 'summarization',\n",
       " ',',\n",
       " 'which',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'obtaining',\n",
       " 'a',\n",
       " 'generic',\n",
       " 'summary',\n",
       " 'or',\n",
       " 'abstract',\n",
       " 'of',\n",
       " 'the',\n",
       " 'collection',\n",
       " '(',\n",
       " 'whether',\n",
       " 'documents',\n",
       " ',',\n",
       " 'or',\n",
       " 'sets',\n",
       " 'of',\n",
       " 'images',\n",
       " ',',\n",
       " 'or',\n",
       " 'videos',\n",
       " ',',\n",
       " 'news',\n",
       " 'stories',\n",
       " 'etc',\n",
       " '.',\n",
       " ')',\n",
       " '.',\n",
       " 'The',\n",
       " 'second',\n",
       " 'is',\n",
       " 'query',\n",
       " 'relevant',\n",
       " 'summarization',\n",
       " ',',\n",
       " 'sometimes',\n",
       " 'called',\n",
       " 'query',\n",
       " '-',\n",
       " 'based',\n",
       " 'summarization',\n",
       " ',',\n",
       " 'which',\n",
       " 'summarizes',\n",
       " 'objects',\n",
       " 'specific',\n",
       " 'to',\n",
       " 'a',\n",
       " 'query',\n",
       " '.',\n",
       " 'Summarization',\n",
       " 'systems',\n",
       " 'are',\n",
       " 'able',\n",
       " 'to',\n",
       " 'create',\n",
       " 'both',\n",
       " 'query',\n",
       " 'relevant',\n",
       " 'text',\n",
       " 'summaries',\n",
       " 'and',\n",
       " 'generic',\n",
       " 'machine',\n",
       " '-',\n",
       " 'generated',\n",
       " 'summaries',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'what',\n",
       " 'the',\n",
       " 'user',\n",
       " 'needs',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'An',\n",
       " 'example',\n",
       " 'of',\n",
       " 'a',\n",
       " 'summarization',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'document',\n",
       " 'summarization',\n",
       " ',',\n",
       " 'which',\n",
       " 'attempts',\n",
       " 'to',\n",
       " 'automatically',\n",
       " 'produce',\n",
       " 'an',\n",
       " 'abstract',\n",
       " 'from',\n",
       " 'a',\n",
       " 'given',\n",
       " 'document',\n",
       " '.',\n",
       " 'Sometimes',\n",
       " 'one',\n",
       " 'might',\n",
       " 'be',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'generating',\n",
       " 'a',\n",
       " 'summary',\n",
       " 'from',\n",
       " 'a',\n",
       " 'single',\n",
       " 'source',\n",
       " 'document',\n",
       " ',',\n",
       " 'while',\n",
       " 'others',\n",
       " 'can',\n",
       " 'use',\n",
       " 'multiple',\n",
       " 'source',\n",
       " 'documents',\n",
       " '(',\n",
       " 'for',\n",
       " 'example',\n",
       " ',',\n",
       " 'a',\n",
       " 'cluster',\n",
       " 'of',\n",
       " 'articles',\n",
       " 'on',\n",
       " 'the',\n",
       " 'same',\n",
       " 'topic',\n",
       " ')',\n",
       " '.',\n",
       " 'This',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'called',\n",
       " 'multi',\n",
       " '-',\n",
       " 'document',\n",
       " 'summarization',\n",
       " '.',\n",
       " 'A',\n",
       " 'related',\n",
       " 'application',\n",
       " 'is',\n",
       " 'summarizing',\n",
       " 'news',\n",
       " 'articles',\n",
       " '.',\n",
       " 'Imagine',\n",
       " 'a',\n",
       " 'system',\n",
       " ',',\n",
       " 'which',\n",
       " 'automatically',\n",
       " 'pulls',\n",
       " 'together',\n",
       " 'news',\n",
       " 'articles',\n",
       " 'on',\n",
       " 'a',\n",
       " 'given',\n",
       " 'topic',\n",
       " '(',\n",
       " 'from',\n",
       " 'the',\n",
       " 'web',\n",
       " ')',\n",
       " ',',\n",
       " 'and',\n",
       " 'concisely',\n",
       " 'represents',\n",
       " 'the',\n",
       " 'latest',\n",
       " 'news',\n",
       " 'as',\n",
       " 'a',\n",
       " 'summary',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'Image',\n",
       " 'collection',\n",
       " 'summarization',\n",
       " 'is',\n",
       " 'another',\n",
       " 'application',\n",
       " 'example',\n",
       " 'of',\n",
       " 'automatic',\n",
       " 'summarization',\n",
       " '.',\n",
       " 'It',\n",
       " 'consists',\n",
       " 'in',\n",
       " 'selecting',\n",
       " 'a',\n",
       " 'representative',\n",
       " 'set',\n",
       " 'of',\n",
       " 'images',\n",
       " 'from',\n",
       " 'a',\n",
       " 'larger',\n",
       " 'set',\n",
       " 'of',\n",
       " 'images.[8',\n",
       " ']',\n",
       " 'A',\n",
       " 'summary',\n",
       " 'in',\n",
       " 'this',\n",
       " 'context',\n",
       " 'is',\n",
       " 'useful',\n",
       " 'to',\n",
       " 'show',\n",
       " 'the',\n",
       " 'most',\n",
       " 'representative',\n",
       " 'images',\n",
       " 'of',\n",
       " 'results',\n",
       " 'in',\n",
       " 'an',\n",
       " 'image',\n",
       " 'collection',\n",
       " 'exploration',\n",
       " 'system',\n",
       " '.',\n",
       " 'Video',\n",
       " 'summarization',\n",
       " 'is',\n",
       " 'a',\n",
       " 'related',\n",
       " 'domain',\n",
       " ',',\n",
       " 'where',\n",
       " 'the',\n",
       " 'system',\n",
       " 'automatically',\n",
       " 'creates',\n",
       " 'a',\n",
       " 'trailer',\n",
       " 'of',\n",
       " 'a',\n",
       " 'long',\n",
       " 'video',\n",
       " '.',\n",
       " 'This',\n",
       " 'also',\n",
       " 'has',\n",
       " 'applications',\n",
       " 'in',\n",
       " 'consumer',\n",
       " 'or',\n",
       " 'personal',\n",
       " 'videos',\n",
       " ',',\n",
       " 'where',\n",
       " 'one',\n",
       " 'might',\n",
       " 'want',\n",
       " 'to',\n",
       " 'skip',\n",
       " 'the',\n",
       " 'boring',\n",
       " 'or',\n",
       " 'repetitive',\n",
       " 'actions',\n",
       " '.',\n",
       " 'Similarly',\n",
       " ',',\n",
       " 'in',\n",
       " 'surveillance',\n",
       " 'videos',\n",
       " ',',\n",
       " 'one',\n",
       " 'would',\n",
       " 'want',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'important',\n",
       " 'and',\n",
       " 'suspicious',\n",
       " 'activity',\n",
       " ',',\n",
       " 'while',\n",
       " 'ignoring',\n",
       " 'all',\n",
       " 'the',\n",
       " 'boring',\n",
       " 'and',\n",
       " 'redundant',\n",
       " 'frames',\n",
       " 'captured',\n",
       " '.',\n",
       " '\\n\\n\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize sentences\n",
    "\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nervous-florist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We must remove punctuation and stopwords\n",
    "\n",
    "punctuation = punctuation + '\\n' + '\\n\\n'\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "alpine-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning\n",
    "\n",
    "word_frequencies = {}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            # first time the word is apear\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "environmental-genetics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'broadly': 1,\n",
       " 'types': 1,\n",
       " 'extractive': 1,\n",
       " 'summarization': 11,\n",
       " 'tasks': 1,\n",
       " 'depending': 2,\n",
       " 'program': 1,\n",
       " 'focuses': 2,\n",
       " 'generic': 3,\n",
       " 'obtaining': 1,\n",
       " 'summary': 4,\n",
       " 'abstract': 2,\n",
       " 'collection': 3,\n",
       " 'documents': 2,\n",
       " 'sets': 1,\n",
       " 'images': 3,\n",
       " 'videos': 3,\n",
       " 'news': 4,\n",
       " 'stories': 1,\n",
       " 'etc': 1,\n",
       " 'second': 1,\n",
       " 'query': 4,\n",
       " 'relevant': 2,\n",
       " 'called': 2,\n",
       " 'based': 1,\n",
       " 'summarizes': 1,\n",
       " 'objects': 1,\n",
       " 'specific': 1,\n",
       " 'Summarization': 1,\n",
       " 'systems': 1,\n",
       " 'able': 1,\n",
       " 'create': 1,\n",
       " 'text': 1,\n",
       " 'summaries': 2,\n",
       " 'machine': 1,\n",
       " 'generated': 1,\n",
       " 'user': 1,\n",
       " 'needs': 1,\n",
       " 'example': 3,\n",
       " 'problem': 2,\n",
       " 'document': 4,\n",
       " 'attempts': 1,\n",
       " 'automatically': 3,\n",
       " 'produce': 1,\n",
       " 'given': 2,\n",
       " 'interested': 1,\n",
       " 'generating': 1,\n",
       " 'single': 1,\n",
       " 'source': 2,\n",
       " 'use': 1,\n",
       " 'multiple': 1,\n",
       " 'cluster': 1,\n",
       " 'articles': 3,\n",
       " 'topic': 2,\n",
       " 'multi': 1,\n",
       " 'related': 2,\n",
       " 'application': 2,\n",
       " 'summarizing': 1,\n",
       " 'Imagine': 1,\n",
       " 'system': 3,\n",
       " 'pulls': 1,\n",
       " 'web': 1,\n",
       " 'concisely': 1,\n",
       " 'represents': 1,\n",
       " 'latest': 1,\n",
       " 'Image': 1,\n",
       " 'automatic': 1,\n",
       " 'consists': 1,\n",
       " 'selecting': 1,\n",
       " 'representative': 2,\n",
       " 'set': 2,\n",
       " 'larger': 1,\n",
       " 'images.[8': 1,\n",
       " 'context': 1,\n",
       " 'useful': 1,\n",
       " 'results': 1,\n",
       " 'image': 1,\n",
       " 'exploration': 1,\n",
       " 'Video': 1,\n",
       " 'domain': 1,\n",
       " 'creates': 1,\n",
       " 'trailer': 1,\n",
       " 'long': 1,\n",
       " 'video': 1,\n",
       " 'applications': 1,\n",
       " 'consumer': 1,\n",
       " 'personal': 1,\n",
       " 'want': 2,\n",
       " 'skip': 1,\n",
       " 'boring': 2,\n",
       " 'repetitive': 1,\n",
       " 'actions': 1,\n",
       " 'Similarly': 1,\n",
       " 'surveillance': 1,\n",
       " 'extract': 1,\n",
       " 'important': 1,\n",
       " 'suspicious': 1,\n",
       " 'activity': 1,\n",
       " 'ignoring': 1,\n",
       " 'redundant': 1,\n",
       " 'frames': 1,\n",
       " 'captured': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "administrative-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out max frequency\n",
    "max_frequency = max(word_frequencies.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "imported-consistency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "mighty-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then normalize the dictionary\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word]/max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "utility-universal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'broadly': 0.09090909090909091, 'types': 0.09090909090909091, 'extractive': 0.09090909090909091, 'summarization': 1.0, 'tasks': 0.09090909090909091, 'depending': 0.18181818181818182, 'program': 0.09090909090909091, 'focuses': 0.18181818181818182, 'generic': 0.2727272727272727, 'obtaining': 0.09090909090909091, 'summary': 0.36363636363636365, 'abstract': 0.18181818181818182, 'collection': 0.2727272727272727, 'documents': 0.18181818181818182, 'sets': 0.09090909090909091, 'images': 0.2727272727272727, 'videos': 0.2727272727272727, 'news': 0.36363636363636365, 'stories': 0.09090909090909091, 'etc': 0.09090909090909091, 'second': 0.09090909090909091, 'query': 0.36363636363636365, 'relevant': 0.18181818181818182, 'called': 0.18181818181818182, 'based': 0.09090909090909091, 'summarizes': 0.09090909090909091, 'objects': 0.09090909090909091, 'specific': 0.09090909090909091, 'Summarization': 0.09090909090909091, 'systems': 0.09090909090909091, 'able': 0.09090909090909091, 'create': 0.09090909090909091, 'text': 0.09090909090909091, 'summaries': 0.18181818181818182, 'machine': 0.09090909090909091, 'generated': 0.09090909090909091, 'user': 0.09090909090909091, 'needs': 0.09090909090909091, 'example': 0.2727272727272727, 'problem': 0.18181818181818182, 'document': 0.36363636363636365, 'attempts': 0.09090909090909091, 'automatically': 0.2727272727272727, 'produce': 0.09090909090909091, 'given': 0.18181818181818182, 'interested': 0.09090909090909091, 'generating': 0.09090909090909091, 'single': 0.09090909090909091, 'source': 0.18181818181818182, 'use': 0.09090909090909091, 'multiple': 0.09090909090909091, 'cluster': 0.09090909090909091, 'articles': 0.2727272727272727, 'topic': 0.18181818181818182, 'multi': 0.09090909090909091, 'related': 0.18181818181818182, 'application': 0.18181818181818182, 'summarizing': 0.09090909090909091, 'Imagine': 0.09090909090909091, 'system': 0.2727272727272727, 'pulls': 0.09090909090909091, 'web': 0.09090909090909091, 'concisely': 0.09090909090909091, 'represents': 0.09090909090909091, 'latest': 0.09090909090909091, 'Image': 0.09090909090909091, 'automatic': 0.09090909090909091, 'consists': 0.09090909090909091, 'selecting': 0.09090909090909091, 'representative': 0.18181818181818182, 'set': 0.18181818181818182, 'larger': 0.09090909090909091, 'images.[8': 0.09090909090909091, 'context': 0.09090909090909091, 'useful': 0.09090909090909091, 'results': 0.09090909090909091, 'image': 0.09090909090909091, 'exploration': 0.09090909090909091, 'Video': 0.09090909090909091, 'domain': 0.09090909090909091, 'creates': 0.09090909090909091, 'trailer': 0.09090909090909091, 'long': 0.09090909090909091, 'video': 0.09090909090909091, 'applications': 0.09090909090909091, 'consumer': 0.09090909090909091, 'personal': 0.09090909090909091, 'want': 0.18181818181818182, 'skip': 0.09090909090909091, 'boring': 0.18181818181818182, 'repetitive': 0.09090909090909091, 'actions': 0.09090909090909091, 'Similarly': 0.09090909090909091, 'surveillance': 0.09090909090909091, 'extract': 0.09090909090909091, 'important': 0.09090909090909091, 'suspicious': 0.09090909090909091, 'activity': 0.09090909090909091, 'ignoring': 0.09090909090909091, 'redundant': 0.09090909090909091, 'frames': 0.09090909090909091, 'captured': 0.09090909090909091}\n"
     ]
    }
   ],
   "source": [
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "verbal-closure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "\n",
      "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on., The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.)., The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query., Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
      "\n",
      ", An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document., Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic)., This problem is called multi-document summarization., A related application is summarizing news articles., Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
      "\n",
      ", Image collection summarization is another application example of automatic summarization., It consists in selecting a representative set of images from a larger set of images.[8], A summary in this context is useful to show the most representative images of results in an image collection exploration system., Video summarization is a related domain, where the system automatically creates a trailer of a long video., This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions., Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.\n",
      "\n",
      "\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# sentences tokenization\n",
    "sentence_tokens = [sent for sent in doc.sents]\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "swiss-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcule the sentences score\n",
    "sentence_scores = {}\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent]  += word_frequencies[word.text.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acquired-example",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       " \n",
       " There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.: 2.818181818181818,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).: 3.9999999999999987,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.: 3.909090909090909,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
       " : 3.09090909090909,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.: 3.9999999999999996,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).: 2.545454545454545,\n",
       " This problem is called multi-document summarization.: 1.8181818181818183,\n",
       " A related application is summarizing news articles.: 1.0909090909090908,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
       " : 2.727272727272727,\n",
       " Image collection summarization is another application example of automatic summarization.: 2.909090909090909,\n",
       " It consists in selecting a representative set of images from a larger set of images.[8]: 1.1818181818181817,\n",
       " A summary in this context is useful to show the most representative images of results in an image collection exploration system.: 1.818181818181818,\n",
       " Video summarization is a related domain, where the system automatically creates a trailer of a long video.: 2.2727272727272725,\n",
       " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.: 1.1818181818181817,\n",
       " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.\n",
       " \n",
       " : 1.4545454545454544}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores\n",
    "# con esto determinamos la importancia dentro del parrafo de la sentencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "substantial-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "small-north",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_length = int(len(sentence_tokens)*0.3)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "helpful-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "gentle-brown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
       " ]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary\n",
    "# the 3 most importances sentecces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "legitimate-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the sentencs\n",
    "\n",
    "final_summary = [word.text for word in summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fitting-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_join =  \" \".join(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dependent-travel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\n\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "painful-evanescence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
      "\n",
      "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
      "\n",
      "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[8] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "breeding-meeting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cordless-stick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1874"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "painful-defeat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-dictionary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
